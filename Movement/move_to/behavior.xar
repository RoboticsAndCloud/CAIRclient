<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Python Script" id="1" localization="8" tooltip="This box contains a basic python script and can be used to create any python script box you would like.&#x0A;&#x0A;To edit its script, double-click on it." x="239" y="84"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[import sys
import qi
import numpy as np
import motion
import argparse
from naoqi import ALProxy
import os


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.gain = 0.2
        self.motionProxy = ALProxy("ALMotion")
        self.motionProxy.wakeUp()
        self.memory = ALProxy("ALMemory")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        self.voice_speed = "\\RSPD=85\\"
        self.configuration = {"bodyLanguageMode": "contextual"}
        self.memory.subscribeToEvent("MiddleTactilTouched", self.getName(), "onTouched")
        self.memory.subscribeToEvent("FrontTactilTouched", self.getName(), "onTouched")
        self.memory.subscribeToEvent("RearTactilTouched", self.getName(), "onTouched")
        self.isRunning = True

    def onTouched(self, strVarName, value):
        self.logger.info("touched")
        self.motionProxy.stopMove()
        self.isRunning = False

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def get_places_from_map(self):
        with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'r') as f:
            lines = f.readlines()

        places = {}
        for line in lines:
            if line != '\n':
                place = line.split('_')[0]
                self.logger.info(str(place))
                X = float(line.split('_')[1])
                Y = float(line.split('_')[2])
                Theta = float(line.split('_')[3])
                places[place] = (X, Y, Theta)
        return places


    def onInput_onStart(self):
        where = str(self.memory.getData("CARESSES/move_to"))
        places = self.get_places_from_map()

        if where in places.keys():
            Px_w = places[where][0]
            Py_w = places[where][1]
            Pz_w = 1.0
            Ptheta_w = places[where][2]
            destination = [Px_w, Py_w, Pz_w, Ptheta_w]
            print "Destination:", destination

            # Try to move to that place only if the it is known!
            odometry = self.motionProxy.getRobotPosition(True)
            Px_r = odometry[0]
            Py_r = odometry[1]
            Ptheta_r = odometry[2]
            P_r = [Px_r, Py_r, 1.0]

            try:
                transformation_matrix = self.memory.getData("CARESSES/transformation_matrix")
                theta = self.memory.getData("CARESSES/theta")
                Pr_w = np.dot(transformation_matrix, np.array([P_r]).T)
                Pr_w = [round(Pr_w[0], 2), round(Pr_w[1], 2), 1.0, round(Ptheta_r + theta, 2)]
                self.logger.info("Position of the robot wrt the world:" + str(Pr_w))

                relative_destination = [dest - robot_pos for dest, robot_pos in zip(destination, Pr_w)]
                self.logger.info("Relative destination:" + str(relative_destination))
                # Difference between destination and current position (just X, Y and Z - no theta)
                theta_rotation = Pr_w[3]

                rotation_matrix = np.array([[np.cos(theta_rotation), np.sin(theta_rotation)],
                                            [-np.sin(theta_rotation), np.cos(theta_rotation)]])

                x_y_relative_dest = np.array([relative_destination[0], relative_destination[1]])
                relative_movement = np.dot(rotation_matrix, x_y_relative_dest.T)
                self.logger.info("Relative movement: " + str(relative_movement) + str(theta_rotation))
                self.animated_speech.say(self.voice_speed + "I'm going to " + where + ".", self.configuration)

                # CHANGE WITH VELOCITIES
                self.motionProxy.moveTo(round(relative_movement[0], 2), round(relative_movement[1], 2), relative_destination[3])

                while self.isRunning and self.motionProxy.moveIsActive():
                    pass

                odometry = self.motionProxy.getRobotPosition(True)
                Px_r = odometry[0]
                Py_r = odometry[1]
                Ptheta_r = odometry[2]
                P_r = [Px_r, Py_r, 1.0]
                Pr_w = np.dot(transformation_matrix, np.array([P_r]).T)
                Pr_w = [round(Pr_w[0], 2), round(Pr_w[1], 2), 1.0, round(Ptheta_r + theta, 2)]
                self.logger.info("Position of the robot wrt the world:" + str(Pr_w))
                self.onInput_onStop()

            except:
                self.animated_speech.say(self.voice_speed + "I need to know where I am with respect to the environment before I can go somewhere.", self.configuration)
                self.onInput_onStop()

        else:
            self.animated_speech.say(self.voice_speed + "I'm sorry I don't know where " + where + " is.", self.configuration)
            self.onInput_onStop()




    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>